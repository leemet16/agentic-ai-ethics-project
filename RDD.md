# Perceptions of Agentic AI in Organizations: Implications for Responsible AI and ROI
## Research Design Document

Lee Ackerman

<lee_ackerman@media-uni.de>

Monday, February 10, 2025

## Table of Contents

1. [Introduction [4](#introduction)](#introduction)
  * [Problem Statement [4](#problem-statement)](#problem-statement)
  * [Research Question [5](#research-question)](#research-question)
  * [Target Audience [5](#target-audience)](#target-audience)
2. [Survey Methodology [5](#survey-methodology)](#survey-methodology)
  * [Survey Design and Considerations [5](#survey-design-and-considerations)](#survey-design-and-considerations)
  * [Participant Recruitment and Sampling Strategy [6](#participant-recruitment-and-sampling-strategy)](#participant-recruitment-and-sampling-strategy)
  * [Ethical Considerations [7](#ethical-considerations)](#ethical-considerations)

  * [Voluntary and Informed Participation [7](#voluntary-and-informed-participation)](#voluntary-and-informed-participation)

[Anonymity and Data Protection
[7](#anonymity-and-data-protection)](#anonymity-and-data-protection)

[Researcher Integrity and Open Science
[8](#researcher-integrity-and-open-science)](#researcher-integrity-and-open-science)

[Bias Mitigation [8](#bias-mitigation)](#bias-mitigation)

[Ethics Review and Peer Input
[8](#ethics-review-and-peer-input)](#ethics-review-and-peer-input)

[Study Limitations [9](#study-limitations)](#study-limitations)

[Sampling Bias & Generalizability
[9](#sampling-bias-generalizability)](#sampling-bias-generalizability)

[Interpretation of Organizational vs. Individual Perspectives
[9](#interpretation-of-organizational-vs.-individual-perspectives)](#interpretation-of-organizational-vs.-individual-perspectives)

[Dynamic Nature of AI and Responsible AI Practices
[9](#dynamic-nature-of-ai-and-responsible-ai-practices)](#dynamic-nature-of-ai-and-responsible-ai-practices)

[Survey Design [9](#survey-design)](#survey-design)

[Introduction and Consent
[10](#introduction-and-consent)](#introduction-and-consent)

[Anonymity and Confidentiality
[10](#anonymity-and-confidentiality)](#anonymity-and-confidentiality)

[Voluntary Participation and Right to Opt Out
[10](#voluntary-participation-and-right-to-opt-out)](#voluntary-participation-and-right-to-opt-out)

[Survey Questions [11](#survey-questions)](#survey-questions)

[Background Information
[11](#background-information)](#background-information)

[Assessing the Need for Responsible AI Framework Adaptation
[12](#assessing-the-need-for-responsible-ai-framework-adaptation)](#assessing-the-need-for-responsible-ai-framework-adaptation)

[Implementation Techniques and Technologies
[12](#implementation-techniques-and-technologies)](#implementation-techniques-and-technologies)

[Impact on Organizational Culture and Practices
[13](#impact-on-organizational-culture-and-practices)](#impact-on-organizational-culture-and-practices)

[Challenges and Future Outlook
[13](#challenges-and-future-outlook)](#challenges-and-future-outlook)

[Perspectives on Responsible AI and Agentic AI Adoption
[13](#perspectives-on-responsible-ai-and-agentic-ai-adoption)](#perspectives-on-responsible-ai-and-agentic-ai-adoption)

[Use of Generative AI in This Research Project
[14](#use-of-generative-ai-in-this-research-project)](#use-of-generative-ai-in-this-research-project)

[Why Use Generative AI?
[15](#why-use-generative-ai)](#why-use-generative-ai)

[Conventional Research Technologies
[15](#conventional-research-technologies)](#conventional-research-technologies)

[Generative AI Tools [15](#generative-ai-tools)](#generative-ai-tools)

[Researcher Positionality and Reflexivity in AI-Assisted Research
[15](#researcher-positionality-and-reflexivity-in-ai-assisted-research)](#researcher-positionality-and-reflexivity-in-ai-assisted-research)

[Acknowledging the Human Researcher as the Central Agent
[16](#acknowledging-the-human-researcher-as-the-central-agent)](#acknowledging-the-human-researcher-as-the-central-agent)

[Positionality and Potential Biases of the Researcher
[16](#positionality-and-potential-biases-of-the-researcher)](#positionality-and-potential-biases-of-the-researcher)

[Addressing AI Tool Bias and Data Source Considerations
[16](#addressing-ai-tool-bias-and-data-source-considerations)](#addressing-ai-tool-bias-and-data-source-considerations)

[Reaffirming Ethical Commitment and Research Integrity
[17](#reaffirming-ethical-commitment-and-research-integrity)](#reaffirming-ethical-commitment-and-research-integrity)

[Addressing AI Bias and Hallucinations in Research
[17](#addressing-ai-bias-and-hallucinations-in-research)](#addressing-ai-bias-and-hallucinations-in-research)

[Data Validation and Analysis
[18](#data-validation-and-analysis)](#data-validation-and-analysis)

[Instrument Validation Approach
[18](#instrument-validation-approach)](#instrument-validation-approach)

[Data Analysis and Interpretation
[18](#data-analysis-and-interpretation)](#data-analysis-and-interpretation)

[Future Use of Data [19](#future-use-of-data)](#future-use-of-data)

[Appendix: Glossary [20](#appendix-glossary)](#appendix-glossary)

# Introduction

This document outlines the design for the research project titled
\"**Perceptions of Agentic AI in Organizations: Implications for
Responsible AI and ROI.**\" The project is being conducted by Lee
Ackerman, M.A. in Artificial Intelligence and Societies, Media
University of Applied Sciences, as part of Artificial Intelligence and
Ethics. For any questions regarding this project, please contact Lee
Ackerman at <lee_ackerman@media-uni.de>.

This research explores the role of agentic AI in organizational
settings, specifically focusing on how organizations perceive and adapt
their responsible AI frameworks to accommodate this new technology. As
the field of AI continues to evolve, agentic AI has emerged as a
critical area of interest. Given the novel nature of agentic AI, it is
crucial to understand how organizations are integrating it into their
responsible AI frameworks.

The following definition serves as a foundation for this research,
establishing a shared understanding of agentic AI and its relevance to
the study.

> **Generative AI Agents (Agentic AI): Generative AI agents, or Agentic
> AI,** are a new class of AI agents that leverage large language models
> (LLMs) and multimodal AI capabilities. These agents exhibit a higher
> degree of autonomy and adaptability, characterized by:

-   **Emergent Behavior:** The ability to generate novel solutions,
    exhibit unexpected behaviors, and adapt to unforeseen challenges.

-   **Multimodal Reasoning:** The capacity to process and integrate
    information from various sources, including text, images, audio, and
    video.

-   **Proactive Planning:** The ability to autonomously plan and execute
    complex tasks, often involving multiple steps and interactions with
    the environment.

-   **Continuous Learning:** The ability to continuously learn and adapt
    based on new information and experiences.

For additional context, a glossary of key terms related to agentic AI
and responsible AI is provided at the end of this document. The glossary
includes definitions and resources for further reading, helping to
clarify terms that are central to this study.

## Problem Statement

The increasing investment in advanced forms of artificial intelligence,
particularly agentic AI, by organizations necessitates a deeper
understanding of their perceptions and evolving practices regarding the
adaptation of responsible AI frameworks. Unlike simpler AI applications,
agentic AI systems present unique challenges and opportunities,
requiring organizations to critically examine their existing responsible
AI approaches. Furthermore, the successful and responsible adoption of
agentic AI hinges, in part, on organizational workforce readiness and
the availability of appropriate skills. This study aims to explore
whether organizations perceive a need to adapt their responsible AI
frameworks specifically for these more sophisticated agentic AI
technologies and how these perceptions influence their implementation of
responsible AI practices and approaches to ROI calculations, including
considerations of workforce skills and capabilities.

## Research Question

How do organizations\' perceptions of agentic AI influence their
implementation of responsible AI practices and their subsequent ROI
calculations?

## Target Audience

This research focuses on professionals working within or alongside large
corporate entities (companies with 5,000+ employees or \$1B+ in annual
revenue) in North America who are actively involved in the strategic
development, deployment, and governance of advanced AI systems,
including agentic AI technologies. This includes individuals from
enterprises as well as consultants, independent firms, and smaller
companies that support AI strategy, development, and governance for
large organizations specifically in the context of increasingly
autonomous and agentic AI applications. To ensure a cross-industry
perspective, participants will be recruited from technology, finance,
healthcare, manufacturing, retail, and other sectors where AI adoption
is shaping business and ethical practices. Participants will include:

-   AI Ethics & Responsible AI Experts (internal and external)

-   AI Consultants & Advisors (ethics, strategy, policy)

-   Product Managers & Product Owners (AI-driven products)

-   AI Developers & Engineers (applied AI, ML specialists)

-   Engineering & IT Leadership (CTOs, CIOs, VPs of AI/Tech)

-   Business & Strategy Leaders (Chief AI Officers, Innovation Leaders,
    CEOs)

-   Legal, Compliance & Governance Professionals (AI risk, regulatory
    affairs)

# Survey Methodology

## Survey Design and Considerations

-   **Concise and User Friendly**: The survey will be designed to be
    concise and user-friendly, estimated to take no more than 15 minutes
    to complete. This brevity is intended to encourage participation
    from busy professionals by minimizing time commitment and ensuring
    ease of engagement.

-   **Anonymous Data Collection**: The survey will be entirely
    anonymous. No personally identifiable information (PII) will be
    collected, and IP addresses or other identifying metadata will not
    be recorded by the survey platform. This robust anonymity is
    designed to encourage candid and honest responses by eliminating
    concerns about personal or organizational identification and
    ensuring confidentiality.

-   **Open Data Sharing (Anonymized)**: In alignment with open science
    principles and to maximize the impact and ethical reuse of this
    research, the anonymized, aggregated dataset will be shared publicly
    via an open repository (e.g., GitHub) upon publication of the
    research findings. This commitment to open data promotes
    transparency, allows for independent verification of findings, and
    encourages further ethical research and analysis by the broader
    research community.

-   **Purposeful Sample Size for Qualitative Depth**: The target sample
    size for this qualitative survey is 40-60 participants. This range
    is considered appropriate for qualitative research aiming to achieve
    **thematic saturation** and elicit rich, in-depth insights from a
    purposefully selected sample \[cite a source on qualitative sample
    sizes if you have one\]. While acknowledging reviewer feedback
    regarding sample size considerations for statistical
    generalizability (addressed further in the \'Limitations\' section),
    this targeted sample size prioritizes the depth and richness of data
    from key informants over broad statistical representation across the
    entire Fortune 500 population.

## Participant Recruitment and Sampling Strategy

To ensure that survey respondents align with the research objectives, a
conscious sampling approach is used. Recruitment will be guided through:

-   **Targeted Distribution via Professional Networks**: The survey
    invitation will be distributed through professional networks,
    including personal contacts and relevant professional groups (e.g.,
    AI ethics communities, industry forums). Clear guidance will be
    provided to network contacts regarding the intended participant
    profile (roles involved in AI strategy, responsible AI, and related
    domains within large organizations) to ensure targeted referrals.

-   **Industry and Organizational Alignment**: Recruitment will be
    primarily targeted towards professionals within Fortune 500
    companies and other large North American enterprises. This focus on
    large organizations is driven by the assumption that these entities
    are more likely to be actively exploring and implementing agentic AI
    technologies and grappling with the associated responsible AI
    challenges, aligning directly with the research focus.

-   **Survey Design as a Screening Tool**: Initial survey questions
    capture role, industry, and AI experience to verify relevance.

-   **Data Quality Monitoring and Recruitment Source Tracking**: Unique
    survey URLs will be utilized for each recruitment channel (direct
    outreach, network referrals, LinkedIn posting) to track response
    sources. This will enable assessment of data integrity across
    different channels and facilitate the potential exclusion of
    low-quality responses or responses from unintended participant
    groups, if necessary. This also allows for analysis of response
    rates and potential source-based response variations (as documented
    further in \'Survey Data Collection Procedures\').

-   **Microsoft Forms**: The Survey was implemented using Microsoft
    Forms.

## Ethical Considerations

This research adheres to ethical best practices to protect participant
anonymity, ensure transparency, and promote responsible data use.

### Voluntary and Informed Participation

-   Participants will be fully informed about the study's purpose,
    estimated time commitment, intended use of the data, and assurance
    of anonymity and confidentiality, as detailed in the survey
    introduction and consent section.

-   Explicit informed consent will be obtained from all participants via
    a clear consent statement presented at the beginning of the survey.

-   Participants will be informed that their responses are voluntary and
    anonymous, and that their anonymized, aggregated data may be used in
    future academic and professional contexts (as detailed in the
    consent statement).

### Anonymity and Data Protection

-   Participant anonymity will be rigorously maintained throughout the
    research process. The survey instrument will not collect any
    personally identifiable information (PII), such as names, job
    titles, or company names. Furthermore, the survey platform will be
    configured to not record IP addresses or other identifying metadata.

-   This robust anonymization process eliminates the possibility of
    linking individual responses to specific participants or
    organizations, thereby protecting participants from potential
    reputational harm, aligning with ethical principles such as those
    outlined in the Common Rule.

-   Collected data will be stored securely on password-protected and
    encrypted systems, accessible only to the primary researcher. For
    open data sharing, the dataset will be meticulously de-identified
    and aggregated to ensure that no individual or organization can be
    identified from the shared data.

-   Any findings used in future academic articles, presentations,
    industry conferences, workshops, and public reports will be
    presented exclusively in aggregate form, further ensuring anonymity
    and mitigating any potential risks of reputational or other harm to
    participants or their organizations.

### Researcher Integrity and Open Science

-   The findings will be used for an academic research paper.

-   The findings from this survey may be used in future academic
    articles, presentations, industry conferences, workshops, and public
    reports to contribute to the broader conversation on responsible AI
    and agentic AI.

-   The raw dataset will be shared via an open repository (e.g., GitHub)
    with appropriate documentation to encourage ethical reuse.

### Bias Mitigation

-   The survey will be carefully designed to avoid biased language and
    ensure inclusivity.

-   Efforts will be made to reach a diverse range of participants within
    the North American technology sector.

-   Furthermore, recognizing the potential for varying interpretations
    of the term \'agentic AI\' across different organizations and
    professional backgrounds, this research employs clear definitions
    (provided in the glossary and survey introduction) as a strategy to
    mitigate potential misunderstandings and ensure a common conceptual
    foundation for participant responses. This focus on terminological
    clarity contributes to the rigor and comparability of the collected
    data.

### Ethics Review and Peer Input

-   The research approach, survey design, and ethical considerations
    will undergo informal peer review by 5-7 trusted colleagues with
    expertise in relevant fields, including AI ethics, research
    methodology, and the subject matter of agentic AI.

-   Feedback from this peer review process will ensure that the study
    aligns with best practices for responsible AI research and that
    ethical standards, including participant privacy and informed
    consent, are rigorously addressed.

-   Any significant ethical concerns raised during the review will be
    carefully documented, and appropriate adjustments will be made to
    the research design to ensure that the study is ethically sound
    before data collection begins.

## Study Limitations

### Sampling Bias & Generalizability

The study's participants are primarily drawn from professional networks,
industry colleagues, and AI governance communities, with a focus on
Fortune 500 companies in North America. As a result, the findings may
not fully reflect the perspectives of smaller organizations, startups,
or those operating in different regulatory environments.

The chosen sample size of approximately 40-60 participants represents a
limitation in terms of statistical generalizability to the entire
population of Fortune 500 organizations. Due to the qualitative nature
of this study and the focus on in-depth insights, the findings are
intended to provide rich, contextualized understandings of
organizational perceptions and practices, rather than statistically
representative generalizations applicable to all Fortune 500 companies.
However, the purposeful and targeted sampling strategy aims to mitigate
this limitation by maximizing the information richness and relevance of
the data obtained from key informants within the target population.

### Interpretation of Organizational vs. Individual Perspectives

A potential limitation of this study is that participants may respond in
ways that align with their organization's stated policies rather than
their personal perspectives. Additionally, individuals may tailor their
responses to reflect organizational expectations or job security
concerns. To mitigate this, the survey is designed to be anonymous,
encouraging honest reflections. While anonymity cannot fully eliminate
response bias, it provides participants with the opportunity to share
their views with reduced pressure to conform to organizational
narratives.

### Dynamic Nature of AI and Responsible AI Practices

The field of AI and responsible AI governance is evolving rapidly. As a
result, participants' perspectives may reflect the current state of
their organization's approach rather than long-term or stable
strategies. Additionally, shifts in regulations, industry standards, or
AI capabilities could influence responses in ways that are difficult to
account for.

# Survey Design 

This section outlines the structure and content of the survey as it will
appear to participants in an online data capture platform (e.g., MS
Forms, Google Forms). The questions and format presented here closely
reflect the participant experience.

In addition to the core survey content, participants will have access to
key definitions, a link to the full glossary (Appendix), and
supplemental resources drawn from the endnotes. These elements ensure
clarity and provide additional context where needed.

## Introduction and Consent

Thank you for participating! This research focuses on agentic AI,
defined as: "advanced AI systems exhibiting autonomy, proactiveness, and
goal-directed behavior, capable of making independent decisions to
achieve objectives". This is distinct from simpler AI applications like
chatbots and AI assistants.

This is part of a research project for a Master\'s program. This
research will help us understand how organizations are adapting their
responsible AI frameworks and assessing the impact of agentic AI on
their return on investment (ROI).

Your responses will provide valuable insights into the current state of
responsible AI practices in the context of agentic AI and will
contribute to the broader conversation on ethical AI adoption.

Estimated completion time: 15 minutes

### Anonymity and Confidentiality

This survey is entirely anonymous. No personally identifiable
information will be collected or stored, and all responses will be
aggregated to ensure privacy. Your answers will only be used for the
purposes of this research study, and no individual data will be shared
in any reports or publications.

We respect your privacy and have taken measures to ensure that your
participation remains confidential. Your honest feedback is essential to
the success of this research.

### Voluntary Participation and Right to Opt Out

Your participation in this survey is entirely voluntary. You may choose
to stop answering questions at any time without any consequence. If you
wish to exit the survey at any point, simply close the survey window or
navigate away from the page.

If you choose to participate, you may skip any questions you prefer not
to answer, and you are free to withdraw at any time without affecting
your relationship with the researcher or any other affiliations.

By proceeding with this survey, you are **explicitly consenting** to the
use of the anonymized, aggregated data collected in this survey for the
purposes described above. This includes potential use in **academic
publications, presentations, and public reports, as well as in
professional articles, industry conferences, workshops, and other
dissemination activities intended to contribute to the broader
understanding and advancement of responsible AI and agentic AI.** Your
participation indicates your informed consent to these terms.

**Glossary**: A Glossary of terms is found in Section 2 and Section 3 of
this survey. If you\'d prefer to access as a separate document, the
glossary is also available via this page at the study\'s GitHub
repository: <https://github.com/leemet16/agentic-ai-ethics-project/blob/main/glossary.md>

**Questions of Concerns:** If you have any questions or concerns
regarding this survey, please feel free to contact the researcher at
<lee_ackerman@media-uni.de>.

## Survey Questions

### Background Information

1.  **What is your role in your organization?** (Select the best answer)

    -   **AI Ethics & Responsible AI Expert**s (internal and external)

    -   **AI Consultants & Advisors** (ethics, strategy, policy)

    -   **Product Managers & Product Owners** (AI-driven products)

    -   **AI Developers & Engineers** (applied AI, ML specialists)

    -   **Engineering & IT Leadership** (CTOs, CIOs, VPs of AI/Tech)

    -   **Business & Strategy Leaders** (Chief AI Officers, Innovation
        Leaders, CEOs)

    -   **Legal, Compliance & Governance Professionals** (AI risk,
        regulatory affairs)

    -   Other (please specify)

2.  **Which industry best describes your organization\'s primary
    sector?** (Select the best answer)

    -   Technology (e.g., AI/ML development, software, IT services)

    -   Finance & Banking (e.g., fintech, investment, insurance)

    -   Healthcare & Life Sciences (e.g., hospitals, pharmaceuticals,
        biotech)

    -   Manufacturing & Industrial (e.g., automotive, electronics, heavy
        industry)

    -   Retail & E-commerce (e.g., consumer goods, online marketplaces)

    -   Telecommunications (e.g., broadband, wireless, network
        infrastructure)

    -   Energy & Utilities (e.g., oil & gas, renewables, power
        distribution)

    -   Public Sector & Government (e.g., regulatory agencies,
        policy-making)

    -   Legal & Compliance (e.g., law firms, AI governance consulting)

    -   Academia & Research (e.g., universities, think tanks, research
        institutions)

    -   Other (please specify):

3.  **How long have you been working with AI technologies?** (Select the
    best answer)

    -   Less than 1 year

    -   1-3 years

    -   3-5 years

    -   5-10 years

    -   More than 10 years

### Assessing the Need for Responsible AI Framework Adaptation

4.  **Do you believe there is a need to enhance your organization\'s
    responsible AI framework to address the complexities of agentic
    AI?** (Select the best answer)

    -   Yes

    -   No

    -   Not sure

5.  **Which dimensions of your responsible AI framework do you perceive
    as most likely needing enhancement for agentic AI?** (Select all
    that apply)

    -   Ethical Guidelines

    -   Transparency Measures

    -   Accountability Mechanisms

    -   Bias Mitigation Strategies

    -   Privacy and Data Protection Protocols

    -   Safety and Security Standards

    -   Stakeholder Engagement Processes

    -   Other (please specify)

### Implementation Techniques and Technologies

6.  **Which of the following implementation techniques and technologies
    has your organization adopted to ensure agentic AI operates
    responsibly?** (Select all that apply)

    -   **Monitoring and Evaluation** (Continuous Monitoring Tools,
        Regular Ethical Audits, Robust Model Validation Processes, ...)

    -   **Transparency and Explainability** (Explainability and
        Transparency Tools, Transparency Reports, ...)

    -   **Human Oversight and Interaction** (Human-in-the-Loop Systems,
        User Feedback Mechanisms, ...)

    -   **Skills Development and Learning (**Technical AI Skills
        Training, Responsible AI Skills Training, Data Governance and
        Management Skills Training, Ethics Training Programs, ...)

    -   **Ethical Decision-Making** (Ethical Decision-Making Frameworks,
        Morality Code Integration, ...)

    -   **Bias and Fairness** (Bias Detection and Mitigation Algorithms,
        Diverse Data Sourcing, ...)

    -   **Data Protection and Privacy** (Data Protection Technologies,
        Privacy and Data Protection Protocols, ...)

    -   **Integrated Development** **Practices** (Cross-Functional
        Development Teams, Stakeholder Engagement Processes, Using New
        Design Patterns, ...)

    -   **Other (please specify):**

### Impact on Organizational Culture and Practices

7.  **How has the implementation of agentic AI influenced your
    organization\'s culture and practices?** (Select all that apply)

    -   Increased focus on ethical considerations

    -   Enhanced collaboration across departments

    -   Greater emphasis on transparency and accountability

    -   Improved training and development programs

    -   Adoption of new technologies and tools

    -   Changes in decision-making processes

    -   No significant impact

    -   Other (please specify):

### Challenges and Future Outlook

8.  **In your view, what is the single most pressing challenge that
    organizations must address when developing or deploying agentic AI
    systems?** (Open-ended)

9.  **What do you think are the future trends in responsible AI,
    especially concerning agentic AI?** (Open-ended)

### Perspectives on Responsible AI and Agentic AI Adoption

10. **Please indicate your level of agreement with the following
    statements:**

-   **Our organization has a clear understanding of the differences
    between agentic AI and generative AI.**

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

-   **Our organization has effectively adapted its responsible AI
    framework to include agentic AI.**

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

-   **Our organization has a clear understanding of how agentic AI
    impacts our responsible AI policies and governance**.

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

-   **Implementing agentic AI has positively influenced our
    organization\'s ROI.**

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

-   **Calculating ROI for agentic AI projects remains a challenge for
    our organization.**

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

-   **Our organization sees a strong connection between responsible AI
    practices and financial performance.**

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

-   **Our organization is well-prepared to adapt to future advancements
    in responsible AI.**

    -   Strongly Agree

    -   Agree

    -   Neutral

    -   Disagree

    -   Strongly Disagree

# Use of Generative AI in This Research Project

This research project leverages a variety of tools and technologies,
including both traditional and advanced AI-driven methods, to explore
the complexities of responsible AI and agentic AI. The integration of
these tools has been instrumental in designing, executing, and analyzing
the study.

## Why Use Generative AI?

This research is not only about exploring responsible AI and agentic AI
but also about understanding how best to collaborate with AI in
performing research. Generative AI has proven to be an invaluable
research partner and assistant, enhancing the efficiency, depth, and
breadth of the study. By integrating AI tools, we aim to demonstrate the
potential of AI to augment human research capabilities, providing a
model for future academic and industry projects.

## Conventional Research Technologies

-   **Google Scholar, arXiv, Academia.edu, EBSCO**: These platforms were
    utilized to search for existing research papers, articles, and blog
    posts. Google Scholar and arXiv are well-known for their academic
    and peer-reviewed content, while Academia.edu serves as a platform
    for researchers to share papers and connect with colleagues. EBSCO,
    known for its comprehensive database of academic journals, articles,
    and other scholarly resources, was also used to ensure the study is
    grounded in current research and best practices from both academic
    and professional perspectives.

## Generative AI Tools

-   **Chats with Copilot, ChatGPT, and Gemini**: Extensive conversations
    with these AI tools played a crucial role in various stages of the
    project. They assisted in:

    -   Designing the project framework and creating the survey.

    -   Providing analyses and critiques of the research approach.

    -   Finding and summarizing content for the literature review.

    -   Drafting emails

    -   Future: Interpreting survey results.

    -   Future: Collaborating on the final paper.

<!-- -->

-   **Consensus**: This tool will be used to work through existing
    research materials, helping to synthesize and validate findings from
    multiple sources.

-   **Data Processing Tools**: Specialized AI tools may be employed to
    process and analyze the data collected from the survey, ensuring
    accurate and insightful results.

## Researcher Positionality and Reflexivity in AI-Assisted Research

In outlining the utilization of Generative AI tools within this research
project, it is paramount to acknowledge the central role of the human
researcher and to critically examine the potential influences of both my
own positionality and the nature of AI technologies themselves. This
subsection addresses these crucial aspects of research methodology,
ensuring transparency and ethical rigor in the application of AI tools.

### Acknowledging the Human Researcher as the Central Agent

While Generative AI tools are employed to augment various stages of this
research -- from literature synthesis to data analysis -- it is
essential to underscore that this study remains fundamentally a
human-led endeavor. As the principal researcher, I am responsible for
defining the research questions, designing the methodology, overseeing
data collection, and, most critically, interpreting the findings. AI
tools serve as instruments to enhance efficiency and explore patterns
within data, but they do not replace the critical human judgment and
scholarly interpretation that are central to qualitative social science
research. The insights and conclusions drawn from this study are
ultimately a product of my analysis and understanding, informed by, but
not dictated by, the outputs of AI technologies.

### Positionality and Potential Biases of the Researcher

Recognizing that research is never conducted from a completely neutral
standpoint, I acknowledge my own positionality and the potential for
inherent biases to shape the research process. As a researcher deeply
embedded in the landscape of AI development and deployment, my
perspectives are informed by a career as a technology practitioner. With
a background in software engineering, extensive experience in guiding
technology design and development, and years of consulting with Fortune
500 organizations, including my current work assisting organizations in
utilizing AI, I bring a practitioner\'s lens to this study. Furthermore,
while based in North America (Canada), I am intentionally pursuing my
Master of Arts in AI and Societies with a university based in Germany.
This deliberate choice reflects a desire to engage with a geographically
and demographically diverse academic environment, fostering exposure to
a broader range of perspectives on AI ethics and societal impacts beyond
a solely North American context. This multifaceted background --
encompassing technical expertise, organizational insights, international
academic exposure, and social science perspectives -- shapes my approach
to investigating organizational perceptions of responsible and agentic
AI practices..

### Addressing AI Tool Bias and Data Source Considerations

A critical element of responsible AI integration in research is the
acknowledgement of potential biases embedded within the AI tools
themselves. The Generative AI tools utilized in this project, as with
many such technologies, are trained on vast datasets that may reflect
specific demographic, geographical, and cultural distributions. As a
reviewer astutely pointed out, many of these datasets are significantly
shaped by US-centric data sources. This raises the important
consideration that the outputs of these tools may inadvertently reflect
biases present in their training data, potentially skewing results or
limiting the scope of insights. Specifically, when using AI for tasks
such as literature review, research design development, qualitative data
analysis (including theme identification), and assisting in the writing
process (encompassing interpretation of results, literature integration,
and drafting of conclusions), I will remain critically aware of this
potential data source bias. I will employ strategies to mitigate this,
including: triangulating AI-generated outputs with conventional research
methods; cross-referencing AI-driven insights with existing scholarship
that considers diverse global perspectives on AI ethics; and explicitly
acknowledging the potential limitations of AI tool outputs in the final
interpretation of findings. This critical engagement with the tools
themselves is essential for responsible and rigorous AI-assisted
research.

### Reaffirming Ethical Commitment and Research Integrity

In conclusion, the integration of Generative AI tools into this research
project is undertaken with a firm commitment to ethical research
practices and scholarly integrity. This commitment extends beyond the
ethical considerations inherent in the research topic of responsible AI
itself, and encompasses the ethical utilization of AI within the
research process. By explicitly acknowledging my positionality,
addressing potential biases within AI tools, and maintaining a reflexive
and critical approach throughout the study, I aim to ensure that this
research is conducted responsibly, transparently, and contributes
meaningfully to the understanding of organizational perceptions and
practices regarding responsible AI in the age of agentic AI. The goal is
to produce insights that are not only academically rigorous but also
ethically sound and valuable for informing responsible AI adoption
within organizations.

## Addressing AI Bias and Hallucinations in Research

Given the integration of Generative AI in various aspects of this
research, it is essential to acknowledge and mitigate potential biases
and hallucinations that may arise.

-   To minimize AI bias, all AI-assisted outputs---such as literature
    summaries, thematic analysis, and draft content---will
    be **critically reviewed** against diverse and reputable sources,
    ensuring that insights are not skewed by underlying biases in AI
    training data. Additionally, steps will be taken to verify that
    AI-generated responses do not disproportionately reflect dominant
    perspectives at the expense of underrepresented viewpoints.

-   To address AI hallucinations, all AI-generated content will
    undergo **rigorous fact-checking**, cross-referenced with primary
    sources, peer-reviewed research, and expert opinions. Where AI is
    used to assist in summarizing qualitative data, **human oversight
    will be maintained** to ensure accurate representation of
    participant responses. This approach ensures that AI serves as a
    research aid rather than an unchecked authority, aligning with the
    study's commitment to **rigor, transparency, and responsible AI
    use.**

# Data Validation and Analysis

## Instrument Validation Approach

-   **Expert Review**: Prior to survey distribution, the survey
    instrument will be reviewed by subject matter experts in responsible
    AI, AI ethics, and organizational ROI analysis. These experts will
    evaluate the content validity of the questions, ensuring alignment
    with established concepts and best practices in the field.

-   **Construct Validity**: The survey design is informed by a thorough
    literature review, ensuring that questions are directly related to
    responsible AI and agentic AI frameworks. The Likert scale questions
    were developed based on established research, ensuring that they are
    measuring the intended constructs.

-   **Face Validity**: The survey instrument will be reviewed for
    clarity and relevance by peers and colleagues to confirm that it is
    understood by the target population and covers the necessary topics.
    Feedback will be used to refine any unclear or irrelevant questions.

## Data Analysis and Interpretation

The data collected through the survey will undergo rigorous analysis to
uncover key insights and trends. The survey includes **Likert-scale
questions**, **multiple-choice questions**, and one **open-ended
question**. For the **quantitative data** (Likert-scale and
multiple-choice responses), I will apply **descriptive statistics** to
summarize the data and identify trends. If necessary, more advanced
techniques such as **regression analysis** will be considered to explore
relationships between variables.

The **qualitative data** from the open-ended question (Question 8,
Future Trends) and from the \'Other (please specify)\' options will be
analyzed using a **thematic analysis** approach. Responses will be
manually coded to identify recurring themes and patterns. Although **AI
tools** will be utilized to help organize and categorize this
qualitative data, all AI-generated insights will undergo **human
review** to ensure they align with the participants\' responses and are
free from **bias** or **hallucinations**. The AI-generated outputs will
be cross-checked with the raw data to ensure the accuracy and integrity
of the analysis.

Given the reliance on **AI tools** for organizing and analyzing data,
human oversight will remain a key element of the process to verify that
the AI\'s insights are ethically sound and accurately reflect the
participants' intended messages. In addition, **secondary sources**
(such as published literature) will be integrated to complement the
primary survey data, further enhancing the **validity** of the findings.

To ensure **reliability**, I will conduct an ongoing review of the
survey responses and analysis, adjusting the interpretation of findings
if necessary. This will help ensure that the insights are comprehensive
and accurately reflect the perspectives of participants. Responses will
also be assessed for relevance and quality, considering factors such as
participant background and the completeness of answers. Although no
pilot test is planned, the **survey instrument** will be continually
evaluated throughout the data collection process to ensure clarity and
consistency in the questions asked.

# Future Use of Data

The findings from this survey may be used in future academic articles,
presentations, industry conferences, workshops, and public reports to
contribute to the broader conversation on responsible AI and agentic AI.
While the data will be presented in aggregate form, no personally
identifiable information will be included. The goal is to share the
insights gleaned from this research with a wider audience across both
academic and professional settings, driving further discussion on best
practices in the field of AI ethics and responsible AI frameworks.

# Appendix: Glossary

This glossary provides definitions for key terms used throughout the
research project to ensure clarity and consistency for all participants.
For those interested in further exploration, endnotes have been included
with additional resources for each term to deepen understanding of the
concepts discussed.

**AI Agent (General Definition):** An AI agent is a software system that
perceives its environment, makes decisions, and takes actions to achieve
predefined goals. AI agents exhibit varying degrees of autonomy, from
simple rule-following to complex self-directed behavior. They utilize
data-driven reasoning and can learn and adapt over time[^1] [^2] [^3]
[^4][^5].

**AI Assistant**: An AI assistant (also known as a virtual or digital
assistant) is a software tool that utilizes AI technologies, including
natural language processing (NLP), machine learning (ML), and large
language models (LLMs), to assist users with specific, often predefined
tasks, answer questions, and provide information. While AI assistants
can be sophisticated in their ability to understand language and execute
commands, they typically operate under user direction and lack the
higher degrees of autonomy and proactive planning characteristic of
agentic AI. These assistants are designed to streamline tasks, enhance
user productivity, and provide convenient, conversational
interactions[^6] [^7] [^8] [^9].

**Accountability**: The responsibility of organizations and individuals
to ensure that AI systems operate ethically and that any negative
impacts are addressed. It involves being answerable for the outcomes of
AI systems[^10] [^11] [^12].

**Autonomy**: The ability of AI systems to operate independently, making
decisions and taking actions without human intervention. It refers to
self-governing freedom and moral independence[^13].

**Bias Mitigation**: Strategies and techniques used to identify, reduce,
and eliminate biases in AI systems to ensure fair and equitable
outcomes. This includes methods like data augmentation and adjusting
optimization functions[^14] [^15] [^16].

**Data Protection**: Measures taken to ensure the privacy and security
of data used and generated by AI systems. This includes safeguarding
sensitive information from data loss, corruption, and unauthorized
access[^17] .

**Ethical AI**: AI systems that adhere to ethical principles, such as
fairness, accountability, transparency, and respect for privacy. This
field studies how to optimize AI\'s beneficial impact while reducing
risks and adverse outcomes[^18] [^19] [^20] [^21].

**Explainability**: The set of processes and methods that allow human
users to comprehend and trust the results and outputs created by AI
systems. Explainable AI (XAI) helps characterize model accuracy,
fairness, transparency, and outcomes in AI-powered decision-making[^22]
[^23] [^24].

**Generative AI Agents (Agentic AI): Generative AI agents, or Agentic
AI,** represent a more advanced category of AI agents that should be
distinguished from simpler AI applications like AI assistants or
chatbots. Generative AI agents leverage large language models (LLMs) and
multimodal AI capabilities. These agents exhibit a higher degree of
autonomy and adaptability, characterized by:

-   **Emergent Behavior:** The ability to generate novel solutions,
    exhibit unexpected behaviors, and adapt to unforeseen challenges.

-   **Multimodal Reasoning:** The capacity to process and integrate
    information from various sources, including text, images, audio, and
    video.

-   **Proactive Planning:** The ability to autonomously plan and execute
    complex tasks, often involving multiple steps and interactions with
    the environment.

-   **Continuous Learning:** The ability to continuously learn and adapt
    based on new information and experiences

-   **Increased Organizational Demands**: Agentic AI systems often
    require more robust data infrastructure, advanced API integrations,
    and specialized organizational skills compared to simpler AI
    applications, raising the bar for successful implementation and
    responsible governance[^25] [^26] [^27] [^28].

**Responsible AI**: The practice of designing, developing, and deploying
AI systems in a way that prioritizes ethics, transparency, and alignment
with societal values. Responsible AI encompasses principles such as
fairness, accountability, transparency, privacy, and inclusivity, aiming
to minimize bias and harm while fostering trust.[^29] [^30] [^31] [^32]
[^33].

**Responsible AI Framework**: A structured and systematic approach
comprising guidelines, principles, and processes that organizations
adopt to ensure their AI systems align with Responsible AI principles.
These frameworks provide actionable standards to guide ethical
decision-making, address risks, and promote accountability throughout
the AI lifecycle.[^34] [^35] [^36] [^37] [^38].

**ROI (Return on Investment)**: A performance measure used to evaluate
the efficiency or profitability of an investment. It is calculated by
dividing the net profit from an investment by its cost, expressed as a
percentage[^39] [^40] [^41] [^42] [^43].

**Stakeholder Engagement**: The process of involving diverse groups of
people, including users, developers, and regulators, in the development
and deployment of AI systems. It ensures that the perspectives and needs
of all stakeholders are considered[^44] [^45].

**Traditional AI Agents:** Traditional AI agents encompass a range of
technologies, including rule-based systems, machine learning models
(such as supervised, unsupervised, and reinforcement learning), and
simple neural networks. Unlike Generative AI Agents, Traditional AI
Agents typically do not leverage large language models (LLMs) or
advanced multimodal AI capabilities. While these agents can learn from
data and exhibit some level of adaptability, their decision-making is
often task-specific and may have limitations in generalizing to novel
situations or adapting to unforeseen circumstances[^46] [^47] [^48]
[^49].

**Transparency**: The quality of being open and clear about the
operations and decision-making processes of AI systems. It involves
making AI systems understandable and accessible to stakeholders[^50]
[^51].

[^1]: Russell, S., & Norvig, P. (2021). Artificial Intelligence: A
    Modern Approach (4th ed.). Pearson. (Chapter 2: Intelligent Agents)

[^2]: Wooldridge, M. (2009). An Introduction to MultiAgent Systems (2nd
    ed.). Wiley. (Chapter 2: Agent Architectures)

[^3]: Amazon Web Services. (n.d.). What are AI agents? Retrieved from
    https://aws.amazon.com/what-is/ai-agents/

[^4]: International Business Machines Corporation (IBM). (n.d.). AI
    agents. Retrieved from

    https://www.ibm.com/think/topics/ai-agents

[^5]: World Economic Forum. (2024, December 16). Navigating the AI
    frontier: A primer on the evolution and impact of AI agents. World
    Economic Forum.
    https://www.weforum.org/publications/navigating-the-ai-frontier-a-primer-on-the-evolution-and-impact-of-ai-agents/

[^6]: International Business Machines Corporation (IBM). (n.d.). AI
    agents vs. AI assistants. Retrieved from

    https://www.ibm.com/think/topics/ai-agents-vs-ai-assistants

[^7]: Danaher, J. (2018). Toward an Ethics of AI Assistants: an Initial
    Framework. *Philosophy & Technology*, 31, 629 - 653.
    https://doi.org/10.1007/s13347-018-0317-3.

[^8]: Iason Gabriel et al. \"The Ethics of Advanced AI
    Assistants.\" *ArXiv*, abs/2404.16244 (2024).
    https://doi.org/10.48550/arXiv.2404.16244.

[^9]: A. Maedche et al. \"AI-Based Digital Assistants.\" *Business &
    Information Systems Engineering*, 61 (2019): 535 - 544.
    https://doi.org/10.1007/s12599-019-00600-8.

[^10]: Sanford, S. (2021, August 11). How to build accountability into
    your AI. Harvard Business Review. Retrieved
    from <https://hbr.org/2021/08/how-to-build-accountability-into-your-ai>

[^11]: Alami, A., & Ernst, N. (2024). Understanding the Building Blocks
    of Accountability in Software Engineering. \[arXiv\]. Retrieved
    February 1, 2025, from <https://arxiv.org/abs/2402.01926>

[^12]: Percy, C., Dragicevic, S., Sarkar, S., & d\'Avila Garcez, A. S.
    (2021). Accountability in AI: From Principles to Industry-specific
    Accreditation. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/2110.09232>

[^13]: Wang, G., & Pea, R. (2024). Algorithmic Autonomy in Data-Driven
    AI. \[arXiv\]. Retrieved from <https://arxiv.org/abs/2411.05210>

[^14]: Uzzi, B. (2020, November). A simple tactic that could help reduce
    bias in AI. Harvard Business Review. Retrieved
    from <https://hbr.org/2020/11/a-simple-tactic-that-could-help-reduce-bias-in-ai>

[^15]: Google Developers. (n.d.). Mitigating bias. Retrieved
    from <https://developers.google.com/machine-learning/crash-course/fairness/mitigating-bias>

[^16]: Krco, N., Laugel, T., Grari, V., Loubes, J.-M., & Detyniecki, M.
    (2024). When mitigating bias is unfair: multiplicity and
    arbitrariness in algorithmic group fairness. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/2302.07185>

[^17]: Microsoft. (n.d.). Data, privacy, and security for Azure OpenAI
    Service. Retrieved
    from <https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy>

[^18]: Thomas, H. (2022, March). Ethics and AI: 3 conversations
    companies need to be having. Harvard Business Review. Retrieved from
    https://hbr.org/2022/03/ethics-and-ai-3-conversations-companies-need-to-be-having

[^19]: Means, G., & Breazeale, J. (2020, October). A practical guide to
    building ethical AI. Harvard Business Review. Retrieved
    from <https://hbr.org/2020/10/a-practical-guide-to-building-ethical-ai>

[^20]: Hagendorff, T. (2019). The Ethics of AI Ethics: An Evaluation of
    Guidelines. \[arXiv\]. Retrieved from
    https://arxiv.org/abs/1903.03425

[^21]: Roberts, J. S., & Montoya, L. N. (2022). Contextualizing
    Artificially Intelligent Morality: A Meta-Ethnography of Top-Down,
    Bottom-Up, and Hybrid Models for Theoretical and Applied Ethics in
    Artificial Intelligence. arXiv. Retrieved from
    https://arxiv.org/abs/2204.07612

[^22]: IBM. (n.d.). Explainable AI. Retrieved
    from <https://www.ibm.com/think/topics/explainable-ai>

[^23]: Palo Alto Networks. (n.d.). AI Explainability. Retrieved
    from <https://www.paloaltonetworks.com/cyberpedia/ai-explainability>

[^24]: Baker, S., & Xiang, W. (2023). Explainable AI is Responsible AI:
    How Explainability Creates Trustworthy and Socially Responsible
    Artificial Intelligence. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/2312.01555>

[^25]: OpenAI. (2023). GPT-4 Technical Report. arXiv preprint.
    \[https://arxiv.org/abs/2303.08774\]
    (https://arxiv.org/abs/2303.08774)

[^26]: Thomas, H. (2024, December). What is Agentic AI, and how will it
    change work? Harvard Business Review. Retrieved from
    https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work

[^27]: NVIDIA Corporation. (2023, August 22). What is Agentic AI?
    \[Nvidia Blog\]. Retrieved from

    https://blogs.nvidia.com/blog/what-is-agentic-ai/

[^28]: Bousetouane, F. (2025). Agentic Systems: A Guide to Transforming
    Industries with Vertical AI Agents. arXiv preprint arXiv:2501.00881.

[^29]: Google Developers. (n.d.). Introduction to Responsible AI.
    Retrieved from
    https://developers.google.com/machine-learning/guides/intro-responsible-ai

[^30]: Lingerfelt, L. (2024, June 5). A three-way comparison: Google,
    Microsoft, and OpenAI\'s responsible AI standards. Lidl IT Blog.
    Retrieved from
    https://itblog.ldlnet.net/index.php/2024/05/22/a-three-way-comparison-google-microsoft-and-openais-responsible-ai-standards/

[^31]: Gartner, Inc. (n.d.). Responsible AI. \[Gartner Glossary\].
    Retrieved from
    https://www.gartner.com/en/information-technology/glossary/responsible-ai

[^32]: International Business Machines Corporation (IBM). (n.d.).
    Responsible AI. Retrieved from
    https://www.ibm.com/think/topics/responsible-ai

[^33]: Clarke, R. (2019). Principles and business processes for
    responsible AI. *Comput. Law Secur. Rev.*, 35, 410-422.
    https://doi.org/10.1016/J.CLSR.2019.04.007.

[^34]: Microsoft. (n.d.). Responsible AI. Retrieved from
    https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai

[^35]: Culbreath, D. (n.d.). The Responsible AI Developer Framework
    (RADF). Retrieved from

    https://radf.dev/

[^36]: Google AI. (n.d.). AI Principles. Retrieved from
    https://ai.google/responsibility/principles/

[^37]: Organisation for Economic Co-operation and Development (OECD).
    (n.d.). AI Principles. Retrieved from

    https://oecd.ai/en/ai-principles

[^38]: Buhmann, A., & Fieseler, C. (2021). Towards a deliberative
    framework for responsible innovation in artificial
    intelligence. *Technology in Society*, 64, 101475.
    https://doi.org/10.1016/J.TECHSOC.2020.101475.

[^39]: DataCamp. (n.d.). ROI of AI: Key Drivers, KPIs, and Challenges.
    Retrieved from https://www.datacamp.com/blog/roi-of-ai

[^40]: ComSoc Tech Blog. (2024, December 14). Will billions of dollars
    big tech is spending on Gen AI data centers produce a decent ROI?
    Retrieved from
    https://techblog.comsoc.org/2024/12/14/will-billions-of-dollars-big-tech-is-spending-on-gen-ai-data-centers-produce-a-decent-roi/

[^41]: Botchkarev, A. (2014). Estimating the Accuracy of the Return on
    Investment (ROI) Performance Evaluations. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/1404.1990>

[^42]: Zambare, N., Idoko, J., Acharya, J., & Ginde, G. (2024). AROhI:
    An Interactive Tool for Estimating ROI of Data Analytics. \[arXiv\].
    Retrieved from <https://arxiv.org/abs/2407.13839>

[^43]: Montreal AI Ethics Institute. (n.d.). The Return on Investment in
    AI Ethics: A Holistic Framework. Retrieved
    from <https://montrealethics.ai/the-return-on-investment-in-ai-ethics-a-holistic-framework/>

[^44]: Rigby, D., First, Z., & O'Keeffe, D. (2023, May). How to create a
    stakeholder strategy: A data-driven approach to design, measurement,
    and implementation. Harvard Business Review. Retrieved
    from <https://hbr.org/2023/05/how-to-create-a-stakeholder-strategy>

[^45]: Alnhari, A. A., & Qureshi, R. (2024). Unified External
    Stakeholder Engagement and Requirements Strategy. \[arXiv\].
    Retrieved from <https://arxiv.org/abs/2409.05019>

[^46]: Newell, A., & Simon, H. A. (1976). Computer Science as Empirical
    Inquiry: Symbols and Search. Communications of the ACM, 19(3),
    113-126.

[^47]: Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An
    Introduction (2nd ed.). MIT Press

[^48]: Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements
    of Statistical Learning: Data Mining, Inference, and Prediction (2nd
    ed.). Springer. (Chapter 1: Introduction)

[^49]: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep
    Learning. MIT Press. (Chapter 1: Introduction)

[^50]: Blackman, R., & Ammanath, B. (2022, June 20). Building
    transparency into AI projects. Harvard Business Review. Retrieved
    from <https://hbr.org/2022/06/building-transparency-into-ai-projects>

[^51]: Candelon, F., Evgeniou, T., & Martens, D. (2023, May 12). AI can
    be both accurate and transparent. Harvard Business Review. Retrieved
    from <https://hbr.org/2023/05/ai-can-be-both-accurate-and-transparent>
