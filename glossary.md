## Glossary

This glossary provides definitions for key terms used throughout the
research project to ensure clarity and consistency for all participants.
For those interested in further exploration, endnotes have been included
with additional resources for each term to deepen understanding of the
concepts discussed.

**AI Agent (General Definition):** An AI agent is a software system that
perceives its environment, makes decisions, and takes actions to achieve
predefined goals. AI agents exhibit varying degrees of autonomy, from
simple rule-following to complex self-directed behavior. They utilize
data-driven reasoning and can learn and adapt over time[^1] [^2] [^3]
[^4][^5].

**AI Assistant**: An AI assistant (also known as a virtual or digital
assistant) is a software tool that utilizes AI technologies, including
natural language processing (NLP), machine learning (ML), and large
language models (LLMs), to assist users with specific, often predefined
tasks, answer questions, and provide information. While AI assistants
can be sophisticated in their ability to understand language and execute
commands, they typically operate under user direction and lack the
higher degrees of autonomy and proactive planning characteristic of
agentic AI. These assistants are designed to streamline tasks, enhance
user productivity, and provide convenient, conversational
interactions[^6] [^7] [^8] [^9].

**Accountability**: The responsibility of organizations and individuals
to ensure that AI systems operate ethically and that any negative
impacts are addressed. It involves being answerable for the outcomes of
AI systems[^10] [^11] [^12].

**Autonomy**: The ability of AI systems to operate independently, making
decisions and taking actions without human intervention. It refers to
self-governing freedom and moral independence[^13].

**Bias Mitigation**: Strategies and techniques used to identify, reduce,
and eliminate biases in AI systems to ensure fair and equitable
outcomes. This includes methods like data augmentation and adjusting
optimization functions[^14] [^15] [^16].

**Data Protection**: Measures taken to ensure the privacy and security
of data used and generated by AI systems. This includes safeguarding
sensitive information from data loss, corruption, and unauthorized
access[^17] .

**Ethical AI**: AI systems that adhere to ethical principles, such as
fairness, accountability, transparency, and respect for privacy. This
field studies how to optimize AI\'s beneficial impact while reducing
risks and adverse outcomes[^18] [^19] [^20] [^21].

**Explainability**: The set of processes and methods that allow human
users to comprehend and trust the results and outputs created by AI
systems. Explainable AI (XAI) helps characterize model accuracy,
fairness, transparency, and outcomes in AI-powered decision-making[^22]
[^23] [^24].

**Generative AI Agents (Agentic AI): Generative AI agents, or Agentic
AI,** represent a more advanced category of AI agents that should be
distinguished from simpler AI applications like AI assistants or
chatbots. Generative AI agents leverage large language models (LLMs) and
multimodal AI capabilities. These agents exhibit a higher degree of
autonomy and adaptability, characterized by:

-   **Emergent Behavior:** The ability to generate novel solutions,
    exhibit unexpected behaviors, and adapt to unforeseen challenges.

-   **Multimodal Reasoning:** The capacity to process and integrate
    information from various sources, including text, images, audio, and
    video.

-   **Proactive Planning:** The ability to autonomously plan and execute
    complex tasks, often involving multiple steps and interactions with
    the environment.

-   **Continuous Learning:** The ability to continuously learn and adapt
    based on new information and experiences

-   **Increased Organizational Demands**: Agentic AI systems often
    require more robust data infrastructure, advanced API integrations,
    and specialized organizational skills compared to simpler AI
    applications, raising the bar for successful implementation and
    responsible governance[^25] [^26] [^27] [^28].

**Responsible AI**: The practice of designing, developing, and deploying
AI systems in a way that prioritizes ethics, transparency, and alignment
with societal values. Responsible AI encompasses principles such as
fairness, accountability, transparency, privacy, and inclusivity, aiming
to minimize bias and harm while fostering trust.[^29] [^30] [^31] [^32]
[^33].

**Responsible AI Framework**: A structured and systematic approach
comprising guidelines, principles, and processes that organizations
adopt to ensure their AI systems align with Responsible AI principles.
These frameworks provide actionable standards to guide ethical
decision-making, address risks, and promote accountability throughout
the AI lifecycle.[^34] [^35] [^36] [^37] [^38].

**ROI (Return on Investment)**: A performance measure used to evaluate
the efficiency or profitability of an investment. It is calculated by
dividing the net profit from an investment by its cost, expressed as a
percentage[^39] [^40] [^41] [^42] [^43].

**Stakeholder Engagement**: The process of involving diverse groups of
people, including users, developers, and regulators, in the development
and deployment of AI systems. It ensures that the perspectives and needs
of all stakeholders are considered[^44] [^45].

**Traditional AI Agents:** Traditional AI agents encompass a range of
technologies, including rule-based systems, machine learning models
(such as supervised, unsupervised, and reinforcement learning), and
simple neural networks. Unlike Generative AI Agents, Traditional AI
Agents typically do not leverage large language models (LLMs) or
advanced multimodal AI capabilities. While these agents can learn from
data and exhibit some level of adaptability, their decision-making is
often task-specific and may have limitations in generalizing to novel
situations or adapting to unforeseen circumstances[^46] [^47] [^48]
[^49].

**Transparency**: The quality of being open and clear about the
operations and decision-making processes of AI systems. It involves
making AI systems understandable and accessible to stakeholders[^50]
[^51].

[^1]: Russell, S., & Norvig, P. (2021). Artificial Intelligence: A
    Modern Approach (4th ed.). Pearson. (Chapter 2: Intelligent Agents)

[^2]: Wooldridge, M. (2009). An Introduction to MultiAgent Systems (2nd
    ed.). Wiley. (Chapter 2: Agent Architectures)

[^3]: Amazon Web Services. (n.d.). What are AI agents? Retrieved from
    https://aws.amazon.com/what-is/ai-agents/

[^4]: International Business Machines Corporation (IBM). (n.d.). AI
    agents. Retrieved from

    https://www.ibm.com/think/topics/ai-agents

[^5]: World Economic Forum. (2024, December 16). Navigating the AI
    frontier: A primer on the evolution and impact of AI agents. World
    Economic Forum.
    https://www.weforum.org/publications/navigating-the-ai-frontier-a-primer-on-the-evolution-and-impact-of-ai-agents/

[^6]: International Business Machines Corporation (IBM). (n.d.). AI
    agents vs. AI assistants. Retrieved from

    https://www.ibm.com/think/topics/ai-agents-vs-ai-assistants

[^7]: Danaher, J. (2018). Toward an Ethics of AI Assistants: an Initial
    Framework. *Philosophy & Technology*, 31, 629 - 653.
    https://doi.org/10.1007/s13347-018-0317-3.

[^8]: Iason Gabriel et al. \"The Ethics of Advanced AI
    Assistants.\" *ArXiv*, abs/2404.16244 (2024).
    https://doi.org/10.48550/arXiv.2404.16244.

[^9]: A. Maedche et al. \"AI-Based Digital Assistants.\" *Business &
    Information Systems Engineering*, 61 (2019): 535 - 544.
    https://doi.org/10.1007/s12599-019-00600-8.

[^10]: Sanford, S. (2021, August 11). How to build accountability into
    your AI. Harvard Business Review. Retrieved
    from <https://hbr.org/2021/08/how-to-build-accountability-into-your-ai>

[^11]: Alami, A., & Ernst, N. (2024). Understanding the Building Blocks
    of Accountability in Software Engineering. \[arXiv\]. Retrieved
    February 1, 2025, from <https://arxiv.org/abs/2402.01926>

[^12]: Percy, C., Dragicevic, S., Sarkar, S., & d\'Avila Garcez, A. S.
    (2021). Accountability in AI: From Principles to Industry-specific
    Accreditation. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/2110.09232>

[^13]: Wang, G., & Pea, R. (2024). Algorithmic Autonomy in Data-Driven
    AI. \[arXiv\]. Retrieved from <https://arxiv.org/abs/2411.05210>

[^14]: Uzzi, B. (2020, November). A simple tactic that could help reduce
    bias in AI. Harvard Business Review. Retrieved
    from <https://hbr.org/2020/11/a-simple-tactic-that-could-help-reduce-bias-in-ai>

[^15]: Google Developers. (n.d.). Mitigating bias. Retrieved
    from <https://developers.google.com/machine-learning/crash-course/fairness/mitigating-bias>

[^16]: Krco, N., Laugel, T., Grari, V., Loubes, J.-M., & Detyniecki, M.
    (2024). When mitigating bias is unfair: multiplicity and
    arbitrariness in algorithmic group fairness. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/2302.07185>

[^17]: Microsoft. (n.d.). Data, privacy, and security for Azure OpenAI
    Service. Retrieved
    from <https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy>

[^18]: Thomas, H. (2022, March). Ethics and AI: 3 conversations
    companies need to be having. Harvard Business Review. Retrieved from
    https://hbr.org/2022/03/ethics-and-ai-3-conversations-companies-need-to-be-having

[^19]: Means, G., & Breazeale, J. (2020, October). A practical guide to
    building ethical AI. Harvard Business Review. Retrieved
    from <https://hbr.org/2020/10/a-practical-guide-to-building-ethical-ai>

[^20]: Hagendorff, T. (2019). The Ethics of AI Ethics: An Evaluation of
    Guidelines. \[arXiv\]. Retrieved from
    https://arxiv.org/abs/1903.03425

[^21]: Roberts, J. S., & Montoya, L. N. (2022). Contextualizing
    Artificially Intelligent Morality: A Meta-Ethnography of Top-Down,
    Bottom-Up, and Hybrid Models for Theoretical and Applied Ethics in
    Artificial Intelligence. arXiv. Retrieved from
    https://arxiv.org/abs/2204.07612

[^22]: IBM. (n.d.). Explainable AI. Retrieved
    from <https://www.ibm.com/think/topics/explainable-ai>

[^23]: Palo Alto Networks. (n.d.). AI Explainability. Retrieved
    from <https://www.paloaltonetworks.com/cyberpedia/ai-explainability>

[^24]: Baker, S., & Xiang, W. (2023). Explainable AI is Responsible AI:
    How Explainability Creates Trustworthy and Socially Responsible
    Artificial Intelligence. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/2312.01555>

[^25]: OpenAI. (2023). GPT-4 Technical Report. arXiv preprint.
    \[https://arxiv.org/abs/2303.08774\]
    (https://arxiv.org/abs/2303.08774)

[^26]: Thomas, H. (2024, December). What is Agentic AI, and how will it
    change work? Harvard Business Review. Retrieved from
    https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work

[^27]: NVIDIA Corporation. (2023, August 22). What is Agentic AI?
    \[Nvidia Blog\]. Retrieved from

    https://blogs.nvidia.com/blog/what-is-agentic-ai/

[^28]: Bousetouane, F. (2025). Agentic Systems: A Guide to Transforming
    Industries with Vertical AI Agents. arXiv preprint arXiv:2501.00881.

[^29]: Google Developers. (n.d.). Introduction to Responsible AI.
    Retrieved from
    https://developers.google.com/machine-learning/guides/intro-responsible-ai

[^30]: Lingerfelt, L. (2024, June 5). A three-way comparison: Google,
    Microsoft, and OpenAI\'s responsible AI standards. Lidl IT Blog.
    Retrieved from
    https://itblog.ldlnet.net/index.php/2024/05/22/a-three-way-comparison-google-microsoft-and-openais-responsible-ai-standards/

[^31]: Gartner, Inc. (n.d.). Responsible AI. \[Gartner Glossary\].
    Retrieved from
    https://www.gartner.com/en/information-technology/glossary/responsible-ai

[^32]: International Business Machines Corporation (IBM). (n.d.).
    Responsible AI. Retrieved from
    https://www.ibm.com/think/topics/responsible-ai

[^33]: Clarke, R. (2019). Principles and business processes for
    responsible AI. *Comput. Law Secur. Rev.*, 35, 410-422.
    https://doi.org/10.1016/J.CLSR.2019.04.007.

[^34]: Microsoft. (n.d.). Responsible AI. Retrieved from
    https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai

[^35]: Culbreath, D. (n.d.). The Responsible AI Developer Framework
    (RADF). Retrieved from

    https://radf.dev/

[^36]: Google AI. (n.d.). AI Principles. Retrieved from
    https://ai.google/responsibility/principles/

[^37]: Organisation for Economic Co-operation and Development (OECD).
    (n.d.). AI Principles. Retrieved from

    https://oecd.ai/en/ai-principles

[^38]: Buhmann, A., & Fieseler, C. (2021). Towards a deliberative
    framework for responsible innovation in artificial
    intelligence. *Technology in Society*, 64, 101475.
    https://doi.org/10.1016/J.TECHSOC.2020.101475.

[^39]: DataCamp. (n.d.). ROI of AI: Key Drivers, KPIs, and Challenges.
    Retrieved from https://www.datacamp.com/blog/roi-of-ai

[^40]: ComSoc Tech Blog. (2024, December 14). Will billions of dollars
    big tech is spending on Gen AI data centers produce a decent ROI?
    Retrieved from
    https://techblog.comsoc.org/2024/12/14/will-billions-of-dollars-big-tech-is-spending-on-gen-ai-data-centers-produce-a-decent-roi/

[^41]: Botchkarev, A. (2014). Estimating the Accuracy of the Return on
    Investment (ROI) Performance Evaluations. \[arXiv\]. Retrieved
    from <https://arxiv.org/abs/1404.1990>

[^42]: Zambare, N., Idoko, J., Acharya, J., & Ginde, G. (2024). AROhI:
    An Interactive Tool for Estimating ROI of Data Analytics. \[arXiv\].
    Retrieved from <https://arxiv.org/abs/2407.13839>

[^43]: Montreal AI Ethics Institute. (n.d.). The Return on Investment in
    AI Ethics: A Holistic Framework. Retrieved
    from <https://montrealethics.ai/the-return-on-investment-in-ai-ethics-a-holistic-framework/>

[^44]: Rigby, D., First, Z., & O'Keeffe, D. (2023, May). How to create a
    stakeholder strategy: A data-driven approach to design, measurement,
    and implementation. Harvard Business Review. Retrieved
    from <https://hbr.org/2023/05/how-to-create-a-stakeholder-strategy>

[^45]: Alnhari, A. A., & Qureshi, R. (2024). Unified External
    Stakeholder Engagement and Requirements Strategy. \[arXiv\].
    Retrieved from <https://arxiv.org/abs/2409.05019>

[^46]: Newell, A., & Simon, H. A. (1976). Computer Science as Empirical
    Inquiry: Symbols and Search. Communications of the ACM, 19(3),
    113-126.

[^47]: Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An
    Introduction (2nd ed.). MIT Press

[^48]: Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements
    of Statistical Learning: Data Mining, Inference, and Prediction (2nd
    ed.). Springer. (Chapter 1: Introduction)

[^49]: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep
    Learning. MIT Press. (Chapter 1: Introduction)

[^50]: Blackman, R., & Ammanath, B. (2022, June 20). Building
    transparency into AI projects. Harvard Business Review. Retrieved
    from <https://hbr.org/2022/06/building-transparency-into-ai-projects>

[^51]: Candelon, F., Evgeniou, T., & Martens, D. (2023, May 12). AI can
    be both accurate and transparent. Harvard Business Review. Retrieved
    from <https://hbr.org/2023/05/ai-can-be-both-accurate-and-transparent>
