## Glossary
This glossary provides definitions for key terms used throughout the research project to ensure clarity and consistency for all participants. For those interested in further exploration, endnotes have been included with additional resources for each term to deepen understanding of the concepts discussed.
- **AI Agent (General Definition)**: An AI agent is a software system that perceives its environment, makes decisions, and takes actions to achieve predefined goals. AI agents exhibit varying degrees of autonomy, from simple rule-following to complex self-directed behavior. They utilize data-driven reasoning and can learn and adapt over time.
- **AI Assistant**: An AI assistant (also known as a virtual or digital assistant) is a software tool that utilizes AI technologies, including natural language processing (NLP), machine learning (ML), and large language models (LLMs), to assist users with specific, often predefined tasks, answer questions, and provide information. While AI assistants can be sophisticated in their ability to understand language and execute commands, they typically operate under user direction and lack the higher degrees of autonomy and proactive planning characteristic of agentic AI.  These assistants are designed to streamline tasks, enhance user productivity, and provide convenient, conversational interactions. 
- **Accountability**: The responsibility of organizations and individuals to ensure that AI systems operate ethically and that any negative impacts are addressed. It involves being answerable for the outcomes of AI systems. 
- **Autonomy**: The ability of AI systems to operate independently, making decisions and taking actions without human intervention. It refers to self-governing freedom and moral independence. 
- **Bias Mitigation**: Strategies and techniques used to identify, reduce, and eliminate biases in AI systems to ensure fair and equitable outcomes. This includes methods like data augmentation and adjusting optimization functions.
- **Data Protection**: Measures taken to ensure the privacy and security of data used and generated by AI systems. This includes safeguarding sensitive information from data loss, corruption, and unauthorized access.
- **Ethical AI**: AI systems that adhere to ethical principles, such as fairness, accountability, transparency, and respect for privacy. This field studies how to optimize AI's beneficial impact while reducing risks and adverse outcomes.
- **Explainability**: The set of processes and methods that allow human users to comprehend and trust the results and outputs created by AI systems. Explainable AI (XAI) helps characterize model accuracy, fairness, transparency, and outcomes in AI-powered decision-making.
- **Generative AI Agents (Agentic AI)**: Generative AI agents, or Agentic AI, represent a more advanced category of AI agents that should be distinguished from simpler AI applications like AI assistants or chatbots. Generative AI agents leverage large language models (LLMs) and multimodal AI capabilities. These agents exhibit a higher degree of autonomy and adaptability, characterized by:
  - Emergent Behavior: The ability to generate novel solutions, exhibit unexpected behaviors, and adapt to unforeseen challenges.
  - Multimodal Reasoning: The capacity to process and integrate information from various sources, including text, images, audio, and video.
  -	Proactive Planning: The ability to autonomously plan and execute complex tasks, often involving multiple steps and interactions with the environment.
  -	Continuous Learning: The ability to continuously learn and adapt based on new information and experiences
  -	Increased Organizational Demands: Agentic AI systems often require more robust data infrastructure, advanced API integrations, and specialized organizational skills compared to simpler AI applications, raising the bar for successful implementation and responsible governance. 
- **Responsible AI**: The practice of designing, developing, and deploying AI systems in a way that prioritizes ethics, transparency, and alignment with societal values. Responsible AI encompasses principles such as fairness, accountability, transparency, privacy, and inclusivity, aiming to minimize bias and harm while fostering trust.
- **Responsible AI Framework**: A structured and systematic approach comprising guidelines, principles, and processes that organizations adopt to ensure their AI systems align with Responsible AI principles. These frameworks provide actionable standards to guide ethical decision-making, address risks, and promote accountability throughout the AI lifecycle.
- **ROI (Return on Investment)**: A performance measure used to evaluate the efficiency or profitability of an investment. It is calculated by dividing the net profit from an investment by its cost, expressed as a percentage.
- **Stakeholder Engagement**: The process of involving diverse groups of people, including users, developers, and regulators, in the development and deployment of AI systems. It ensures that the perspectives and needs of all stakeholders are considered.
- **Traditional AI Agents**: Traditional AI agents encompass a range of technologies, including rule-based systems, machine learning models (such as supervised, unsupervised, and reinforcement learning), and simple neural networks. Unlike Generative AI Agents, Traditional AI Agents typically do not leverage large language models (LLMs) or advanced multimodal AI capabilities. While these agents can learn from data and exhibit some level of adaptability, their decision-making is often task-specific and may have limitations in generalizing to novel situations or adapting to unforeseen circumstances. 
- **Transparency**: The quality of being open and clear about the operations and decision-making processes of AI systems. It involves making AI systems understandable and accessible to stakeholders.
